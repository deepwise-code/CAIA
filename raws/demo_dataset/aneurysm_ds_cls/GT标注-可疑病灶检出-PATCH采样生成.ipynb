{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T06:38:16.553843Z",
     "start_time": "2021-10-12T06:38:16.550583Z"
    }
   },
   "source": [
    "#### 说明\n",
    "* 功能：针对分类模型训练，生成离线采样样本及其它评测结果\n",
    "    * 分割方法输出概率[0,1]范围映射到[0, 10000], 采样实际保留病灶阈值0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:26:59.835962Z",
     "start_time": "2021-11-11T07:26:58.361286Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage import measure\n",
    "from joblib import Parallel,delayed\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:26:59.845224Z",
     "start_time": "2021-11-11T07:26:59.838231Z"
    }
   },
   "outputs": [],
   "source": [
    "#分3个目录，分别处理训练、验证、测试3个分组的处理结果\n",
    "data_group = {\n",
    "    'train': './src/part_train.txt',\n",
    "    'valid': './src/part_valid.txt',\n",
    "    'test': './src/part_test.txt',\n",
    "}\n",
    "ground_truth_mask_root_map = {\n",
    "    'train': './src/mask',\n",
    "    'valid': './src/mask',\n",
    "    'test': './src/mask',\n",
    "} # 标注结果，实例化病灶，注意不同类别对应的病灶含义\n",
    "\n",
    "# lesion_info_path_list = [\n",
    "#     # './src/lesion_level_group_infos.json'\n",
    "# ]\n",
    "\n",
    "image_root_map = {\n",
    "    'train': './src/image',\n",
    "    'valid': './src/image',\n",
    "    'test': './src/image',\n",
    "\n",
    "}\n",
    "\n",
    "segmentation_prob_root_map = {\n",
    "    'train': './src/prob', \n",
    "    'valid': './src/prob', \n",
    "    'test': './src/prob', \n",
    "} # 分割概率值结果, _prob.nii.gz\n",
    "\n",
    "\n",
    "save_root = './P0.3_wwwl_800_300_lesion_match_s3s36'\n",
    "\n",
    "\n",
    "# ww_wl = 1200, 400\n",
    "ww_wl = 800, 300 # 工程化代码\n",
    "shape_norm = (36,)*3 # 归一化大小\n",
    "used_ctx_scale = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:26:59.855616Z",
     "start_time": "2021-11-11T07:26:59.846794Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载分组清单\n",
    "def load_subjects(file_path):\n",
    "    subjects = []\n",
    "    with open(file_path, 'r') as fin:\n",
    "        for line in fin.readlines():\n",
    "            line = line.rstrip()\n",
    "            subjects += [line]\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.309815Z",
     "start_time": "2021-11-11T07:26:59.857277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- 0 train ----------------\n",
      "提取分组记录项： 1\n",
      "---------------- 1 valid ----------------\n",
      "提取分组记录项： 1\n",
      "---------------- 2 test ----------------\n",
      "提取分组记录项： 1\n",
      "================================\n",
      "有效提取结果：\n",
      "组名\t数量\n",
      "train\t1\n",
      "valid\t1\n",
      "test\t1\n"
     ]
    }
   ],
   "source": [
    "#数据一致性验证\n",
    "params_group_map = {}\n",
    "for group_index,group_name in enumerate(data_group.keys()):\n",
    "    print('{0} {1} {2} {0}'.format('-'*16, group_index, group_name))\n",
    "    params_group_map[group_name] = {}\n",
    "    \n",
    "    subject_info_path = data_group[group_name]    \n",
    "    image_root = image_root_map[group_name]\n",
    "    gt_mask_root = ground_truth_mask_root_map[group_name]\n",
    "    seg_prob_root = segmentation_prob_root_map[group_name]\n",
    "    \n",
    "    subject_list = load_subjects(subject_info_path)\n",
    "    print('提取分组记录项：', len(subject_list))\n",
    "    for subject in subject_list:\n",
    "        image_path = os.path.join(image_root, '{}.nii.gz'.format(subject))\n",
    "        gt_mask_path = os.path.join(gt_mask_root, '{}_mask.nii.gz'.format(subject)) # 实例化且转换标记的mask\n",
    "        seg_prob_path = os.path.join(seg_prob_root, '{}_prob.nii.gz'.format(subject))\n",
    "        \n",
    "        assert os.path.exists(image_path), 'not found image in: {}'.format(image_path)\n",
    "        assert os.path.exists(gt_mask_path), 'not found gt mask in : {}'.format(gt_mask_path)  \n",
    "        assert os.path.exists(seg_prob_path), 'not found seg prob matrix in : {}'.format(seg_prob_path)\n",
    "        param = [subject, image_path, gt_mask_path, seg_prob_path]\n",
    "        params_group_map[group_name][subject] = param\n",
    "        \n",
    "#汇总：\n",
    "print('='*32)\n",
    "print('有效提取结果：')\n",
    "print('\\t'.join(['组名', '数量']))\n",
    "for group_name, group_params in params_group_map.items():\n",
    "    print('\\t'.join([group_name, str(len(group_params))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.316199Z",
     "start_time": "2021-11-11T07:27:02.312039Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#C1.1验证数据尺度一致&是否病灶分裂（不连续）\n",
    "def check_shape_consistance(param):\n",
    "    subject, image_path, gt_mask_path, seg_prob_path = param\n",
    "    nii_img = nib.load(image_path)\n",
    "    nii_gt = nib.load(gt_mask_path)\n",
    "    nii_prob = nib.load(seg_prob_path)\n",
    "    shape_list = [nii_img.shape, nii_gt.shape, nii_prob.shape]\n",
    "    if shape_list[0] == shape_list[1] == shape_list[2]:\n",
    "        return True, subject\n",
    "    else:\n",
    "        print('尺寸不一致：{}'.format(shape_list))\n",
    "        return False, subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.388266Z",
     "start_time": "2021-11-11T07:27:02.322145Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# 加载病灶属性信息\n",
    "lesion_info_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.397483Z",
     "start_time": "2021-11-11T07:27:02.390164Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "#C1.2验证数据尺度一致&是否病灶分裂（不连续）\n",
    "def check_gt_inst_mask_lesion_connectd(param, lesion_info):\n",
    "    subject, image_path, gt_mask_path, seg_prob_path = param\n",
    "    nii_gt = nib.load(gt_mask_path)\n",
    "    inst_mask = nii_gt.get_data()\n",
    "    inst_props = measure.regionprops(inst_mask)\n",
    "    assert len(inst_props) == len(lesion_info[subject]), '病灶记录数不一致：{} vs {} in {}'.format(\\\n",
    "                                                          len(inst_props), len(lesion_info[subject]), subject)\n",
    "    check_lesion_split_status = False\n",
    "    for _prop in inst_props:\n",
    "        inst_label = _prop.label\n",
    "        lesion_mask = _prop.image.astype(np.uint8)\n",
    "        lesion_mask_re_inst_mask = measure.label(lesion_mask, connectivity=2) # 2:3D图像 8联通\n",
    "        lesion_mask_re_inst_props = measure.regionprops(lesion_mask_re_inst_mask)\n",
    "        if len(lesion_mask_re_inst_props) != 1:\n",
    "            lesion_split_info = [(_.label, _.area) for _ in lesion_mask_re_inst_props]\n",
    "            print('病灶分裂：', inst_label, '分裂信息：', lesion_split_info, subject)\n",
    "            check_lesion_split_status = True\n",
    "    return check_lesion_split_status, subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.407251Z",
     "start_time": "2021-11-11T07:27:02.403290Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_ww_wl(image, ww=800, wc=300, is_uint8=True):\n",
    "    \"\"\"\n",
    "    adjust window width and window center to get proper input\n",
    "    \"\"\"\n",
    "    min_hu = wc - (ww / 2)\n",
    "    max_hu = wc + (ww / 2)\n",
    "    new_image = np.clip(image, min_hu, max_hu)  # np.copy(image)\n",
    "    if is_uint8:\n",
    "        new_image -= min_hu\n",
    "        new_image = np.array(new_image / ww * 255., dtype=np.uint8)\n",
    "    return new_image\n",
    "\n",
    "def get_auto_size(bbox_size, ctx_scale=3., min_size=36, max_size=96):\n",
    "    baseline = max(bbox_size)\n",
    "    # target_size = max(min_size, int(baseline * ctx_scale))\n",
    "    target_size = min(max_size, max(min_size, int(baseline * ctx_scale)))\n",
    "    return target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.416933Z",
     "start_time": "2021-11-11T07:27:02.409063Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def crop_one_patch_from_image(info, img_xyz, gen_desc=True):\n",
    "    # 病灶-层 裁减范围信息\n",
    "    recall_lesion_label, lesion_label, lesion_slice_index, \\\n",
    "    w,h,target_size, cx, cy, cz, src_desc, cls_desc, slice_prob = info\n",
    "    \n",
    "    #确定裁减范围\n",
    "    sx = int(round(cx - target_size / 2))\n",
    "    sy = int(round(cy - target_size / 2))\n",
    "    sz = int(round(cz - target_size / 2))\n",
    "    ex = int(sx + target_size)\n",
    "    ey = int(sy + target_size)\n",
    "    ez = int(sz + target_size)\n",
    "    # 填充矩阵偏移: 左边界超过范围\n",
    "    offset_sx = 0 if sx >= 0 else - sx\n",
    "    offset_sy = 0 if sy >= 0 else - sy\n",
    "    offset_sz = 0 if sz >= 0 else - sz\n",
    "    image_crop_patch = np.zeros((target_size,) * 3, dtype=np.uint8)\n",
    "\n",
    "    crop_image = img_xyz[max(0, sx): ex, max(0, sy): ey, max(0, sz): ez]\n",
    "    c_w, c_h, c_d = crop_image.shape  # actually crop range\n",
    "    image_crop_patch[offset_sx:, offset_sy:, offset_sz:][:c_w, :c_h, :c_d] = crop_image[...]\n",
    "    \n",
    "    #3D转2D保存： 通道调整 xyz=>zyx\n",
    "    image_crop_patch_transpose = np.transpose(image_crop_patch, (2, 1, 0))  # w,h,d => d, h, w\n",
    "    d, h, w = image_crop_patch_transpose.shape # d,w,h=target_size\n",
    "    image_crop_patch_transpose_2d = image_crop_patch_transpose.reshape(d * h, w)\n",
    "    \n",
    "    desc_info = 'x{0}_y{1}_z{2}_w{3}_h{3}_d{3}_s{4:.2f}_{5}_{6}_{7}_{8}'.format(\n",
    "        int(cx), int(cy), int(cz), target_size,\n",
    "        slice_prob, src_desc, cls_desc,\n",
    "        lesion_label, recall_lesion_label, # 对应的GT实例化病灶(对于检出是召回，对于GT是自己) #,病灶记录,层信息有些重复\n",
    "    )\n",
    "    \n",
    "    \n",
    "    img_crop_3d_xyz, img_crop_2d_zy_x = image_crop_patch, image_crop_patch_transpose_2d\n",
    "    if gen_desc:\n",
    "        return img_crop_3d_xyz, img_crop_2d_zy_x, desc_info\n",
    "    else:\n",
    "        return img_crop_3d_xyz, img_crop_2d_zy_x\n",
    "   \n",
    "# test\n",
    "# crop_one_patch_from_image(info=lesion_slice_info_list[0], img_xyz=img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.422752Z",
     "start_time": "2021-11-11T07:27:02.418882Z"
    }
   },
   "outputs": [],
   "source": [
    "def interp_image(img_xyz, new_shape_xyz):\n",
    "    dtype = img_xyz.dtype\n",
    "    img_xyz_5d = torch.from_numpy(img_xyz[None, None].astype(np.float32))\n",
    "    img_xyz_3d = F.interpolate(img_xyz_5d, new_shape_xyz, mode='trilinear', align_corners=False).data[0, 0].numpy().astype(dtype)\n",
    "    #3D转2D保存： 通道调整 xyz=>zyx\n",
    "    img_transpose = np.transpose(img_xyz_3d, (2, 1, 0))  # w,h,d => d, h, w\n",
    "    d, h, w = img_transpose.shape\n",
    "    img_zy_x_2d = img_transpose.reshape(d * h, w)\n",
    "    \n",
    "    return img_xyz_3d, img_zy_x_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.431060Z",
     "start_time": "2021-11-11T07:27:02.424697Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gt_lesion_slice_info(inst_mask, inst_props):\n",
    "    lesion_slice_info_list = []\n",
    "    lesion_slice_mask_voxel_threshold = 3\n",
    "    for _prop in inst_props:\n",
    "        lesion_label = _prop.label\n",
    "        x0,y0,z0,x1,y1,z1 = _prop.bbox\n",
    "        lesion_mask = (inst_mask==lesion_label).astype(np.uint8)\n",
    "        # 逐层计算大小\n",
    "        for lesion_slice_index in range(z0, z1):\n",
    "            lesion_slice_mask = lesion_mask[..., lesion_slice_index].copy()\n",
    "            slice_voxel_count = (lesion_slice_mask != 0).sum()\n",
    "            if slice_voxel_count < lesion_slice_mask_voxel_threshold: # 太小,跳过此层面,要求至少3个体素\n",
    "                print('此层面病灶面积太小，跳过[GT]：', lesion_label, lesion_slice_index, slice_voxel_count, subject)\n",
    "                continue\n",
    "            lesion_inst_prop = measure.regionprops(lesion_slice_mask)\n",
    "            lesion_used_prop = lesion_inst_prop[0]\n",
    "            _lx0,_ly0,_lx1,_ly1 = lesion_used_prop.bbox\n",
    "            w, h = _lx1 - _lx0, _ly1 - _ly0\n",
    "            target_size = get_auto_size((w, h), ctx_scale=used_ctx_scale)\n",
    "            cx, cy = (_lx0 + _lx1) / 2, (_ly0 + _ly1) / 2\n",
    "            cz = lesion_slice_index  \n",
    "            src_desc = 'gt'\n",
    "            cls_desc = 'pos'\n",
    "            slice_prob = 1.0\n",
    "            gt_recall_lesion_label = lesion_label\n",
    "            slice_lesion_bbox_param = [\n",
    "                gt_recall_lesion_label, lesion_label, lesion_slice_index, \n",
    "                w,h,target_size, cx, cy, cz, \n",
    "                src_desc, cls_desc, slice_prob\n",
    "            ]\n",
    "            #print(slice_lesion_bbox_param)\n",
    "            lesion_slice_info_list += [slice_lesion_bbox_param]\n",
    "\n",
    "    #     break\n",
    "    #pprint(lesion_slice_info_list)\n",
    "    return lesion_slice_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.447748Z",
     "start_time": "2021-11-11T07:27:02.432869Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.提取SEG层病灶信息\n",
    "# 还有其他方式计算召回\n",
    "def get_seg_lesion_slice_info(gt_inst_mask, prob_data, prob_threshold, subject, base_threshold=0.1, verbose=0):\n",
    "    prob_data = (prob_data / 10000.).astype(np.float32) # [0-10000] => [0-1]\n",
    "    #bin_mask = (prob_data >= prob_threshold).astype(np.uint8)\n",
    "    #转换\n",
    "    #prob_data[prob_data<base_threshold] = 0 # 清理一下概率\n",
    "    bin_mask = (prob_data >= base_threshold).astype(np.uint8)    \n",
    "    inst_mask = measure.label(bin_mask, connectivity=2)  # 1: 四联通, 2:八连通\n",
    "    inst_props = measure.regionprops(inst_mask)\n",
    "    # 保留范围内, 最大概率低于指定阈值\n",
    "    pass_lesion_index_list = []\n",
    "    for _prop in inst_props:\n",
    "        max_prob = np.max(prob_data[inst_mask == _prop.label])\n",
    "        if max_prob < prob_threshold: # 无效病灶清除\n",
    "            bin_mask[inst_mask == _prop.label] = 0\n",
    "            inst_mask[inst_mask == _prop.label] = 0\n",
    "            pass_lesion_index_list += [_prop.label]\n",
    "    \n",
    "    # 重新计算\n",
    "    #inst_props = measure.regionprops(inst_mask)\n",
    "    inst_props = [_ for _ in inst_props if _.label not in pass_lesion_index_list]\n",
    "    # print(len(inst_props))\n",
    "    # 清理无效的病灶, 并构建映射信息\n",
    "    seg_inst_lesion_recall_map = {}\n",
    "    for _prop in inst_props:\n",
    "        #print(_prop.label, _prop.area, _prop.bbox)\n",
    "        x0, y0, z0, x1, y1, z1 = _prop.bbox\n",
    "        w, h, d = x1 - x0, y1 - y0, z1 - z0\n",
    "        if _prop.area < 10 or any(_ < 2 for _ in (w, h, d)):\n",
    "            # 无效病灶, 清除\n",
    "            if verbose: print('无效病灶, 清除', _prop.label, _prop.area, _prop.bbox, subject)\n",
    "            bin_mask[inst_mask == _prop.label] = 0\n",
    "            inst_mask[inst_mask == _prop.label] = 0\n",
    "            continue\n",
    "        # pass big lesion\n",
    "        elif _prop.area >= 20000:\n",
    "            output = '异常超巨大病灶, 注意: {} {} {} {}'.format(_prop.label, _prop.area, _prop.bbox, subject)\n",
    "            print(\"\\033[31m{}\\033[0m\".format(output))\n",
    "#             bin_mask[inst_mask == _prop.label] = 0\n",
    "#             inst_mask[inst_mask == _prop.label] = 0\n",
    "            \n",
    "        #建立GT病灶召回映射\n",
    "        seg_inst_label = _prop.label\n",
    "        match_gt_lesion_list = np.unique(gt_inst_mask[inst_mask == _prop.label]).tolist()\n",
    "        match_gt_lesion_list = sorted([str(_) for _ in match_gt_lesion_list if 0 != _]) # int => str\n",
    "        match_gt_lesion_count = len(match_gt_lesion_list)\n",
    "        if match_gt_lesion_count == 0:\n",
    "            seg_inst_lesion_recall_map[seg_inst_label] = '0' # 0\n",
    "        elif match_gt_lesion_count == 1:\n",
    "            seg_inst_lesion_recall_map[seg_inst_label] = match_gt_lesion_list[0]\n",
    "        else:\n",
    "            print('\\033[34m[warning]match more than one, use small/all?:\\033[0m', _prop.area, seg_inst_label, '=>', match_gt_lesion_list, subject)\n",
    "            #排除此种\n",
    "            # 仅保留最小的\n",
    "            #seg_inst_lesion_recall_map[seg_inst_label] = match_gt_lesion_list[0]\n",
    "            # 建立一对多            \n",
    "            seg_inst_lesion_recall_map[seg_inst_label] = \"&\".join(match_gt_lesion_list)\n",
    "\n",
    "    #print(seg_inst_lesion_recall_map)\n",
    "\n",
    "    lesion_slice_info_list = []\n",
    "    lesion_slice_mask_voxel_threshold = 3\n",
    "    for _prop in inst_props:\n",
    "        seg_inst_label = _prop.label\n",
    "        if seg_inst_label not in seg_inst_lesion_recall_map:\n",
    "            if verbose: print('病灶排除，跳过[SEG]：', seg_inst_label)\n",
    "            continue\n",
    "        recall_lesion_label = seg_inst_lesion_recall_map[seg_inst_label]\n",
    "        #print(seg_inst_label, recall_lesion_label)\n",
    "        x0,y0,z0,x1,y1,z1 = _prop.bbox\n",
    "        lesion_mask = (inst_mask==seg_inst_label).astype(np.uint8)\n",
    "        # 逐层计算大小\n",
    "        for lesion_slice_index in range(z0, z1):\n",
    "            lesion_slice_mask = lesion_mask[..., lesion_slice_index].copy()\n",
    "            slice_voxel_count = (lesion_slice_mask != 0).sum()\n",
    "            if slice_voxel_count < lesion_slice_mask_voxel_threshold: # 太小,跳过此层面,要求至少3个体素\n",
    "                if verbose: print('此层面病灶面积太小，跳过[SEG]：', seg_inst_label, lesion_slice_index, slice_voxel_count, subject)\n",
    "                continue\n",
    "            lesion_inst_prop = measure.regionprops(lesion_slice_mask)\n",
    "            lesion_used_prop = lesion_inst_prop[0]\n",
    "            _lx0,_ly0,_lx1,_ly1 = lesion_used_prop.bbox\n",
    "            w, h = _lx1 - _lx0, _ly1 - _ly0\n",
    "            target_size = get_auto_size((w, h), ctx_scale=used_ctx_scale)\n",
    "            cx, cy = (_lx0 + _lx1) / 2, (_ly0 + _ly1) / 2\n",
    "            cz = lesion_slice_index  \n",
    "            src_desc = 'seg'\n",
    "            cls_desc = ['pos','neg'][recall_lesion_label=='0'] # int => str\n",
    "            slice_prob = np.max(prob_data[...,lesion_slice_index][lesion_slice_mask!=0])\n",
    "            slice_lesion_bbox_param = [\n",
    "                recall_lesion_label, seg_inst_label, lesion_slice_index, \n",
    "                w,h,target_size, cx, cy, cz, \n",
    "                src_desc, cls_desc, slice_prob\n",
    "            ]\n",
    "            #print(slice_lesion_bbox_param)\n",
    "            lesion_slice_info_list += [slice_lesion_bbox_param]\n",
    "\n",
    "    #     break\n",
    "    #pprint(lesion_slice_info_list)\n",
    "    return lesion_slice_info_list, inst_mask\n",
    "    \n",
    "\n",
    "# seg_lesion_slice_info_list = get_gt_lesion_slice_info(inst_mask, inst_props)\n",
    "\n",
    "# lesion_slice_info_list = gt_lesion_slice_info_list #+seg_lesion_slice_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.458272Z",
     "start_time": "2021-11-11T07:27:02.449576Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_one_group_data(group_name, param):\n",
    "    #数据处理\n",
    "    #gt/seg 动脉瘤类别标注不同，分别处理\n",
    "    subject, image_path, gt_mask_path, seg_prob_path = param\n",
    "\n",
    "    nii_mask_gt = nib.load(gt_mask_path)\n",
    "    inst_mask = np.asarray(nii_mask_gt.dataobj)\n",
    "    inst_props = measure.regionprops(inst_mask)\n",
    "    # 1.提取GT层病灶信息\n",
    "    gt_lesion_slice_info_list = get_gt_lesion_slice_info(inst_mask, inst_props)\n",
    "    gt_inst_mask = inst_mask # SEG计算匹配召回使用!\n",
    "\n",
    "    #2.提取SEG的Prob信息\n",
    "    prob_threshold = 0.3\n",
    "    nii_seg_prob = nib.load(seg_prob_path)\n",
    "    seg_prob = np.asarray(nii_seg_prob.dataobj)\n",
    "    seg_lesion_slice_info_list, seg_inst_mask_filter = get_seg_lesion_slice_info(gt_inst_mask, seg_prob, prob_threshold, subject)\n",
    "    seg_save_root = os.path.join(save_root, 'prob2seg_with_filter', group_name)\n",
    "    seg_name = '{}_seg.nii.gz'.format(subject)\n",
    "    os.makedirs(seg_save_root, exist_ok=True)\n",
    "    seg_save_full_path = os.path.join(seg_save_root, seg_name)\n",
    "    nii_seg = nib.Nifti1Image(seg_inst_mask_filter.astype(np.uint8), nii_seg_prob.affine)\n",
    "    nii_seg.to_filename(seg_save_full_path)\n",
    "    \n",
    "    \n",
    "    # 合并病灶信息\n",
    "    lesion_slice_info_list = gt_lesion_slice_info_list + seg_lesion_slice_info_list\n",
    "\n",
    "    # 图像加载&归一化\n",
    "    nii_img = nib.load(image_path)\n",
    "    img_ori = np.asanyarray(nii_img.dataobj)\n",
    "    WW, WL = ww_wl\n",
    "    img_norm = adjust_ww_wl(img_ori, ww=WW, wc=WL, is_uint8=True) # 裁减&归一化，uint8,[0,255]\n",
    "\n",
    "\n",
    "    # 开始采样\n",
    "    group_data_info_list = []\n",
    "    for slice_info in lesion_slice_info_list:\n",
    "        img_crop_3d_xyz, img_crop_2d_zy_x, desc_info = crop_one_patch_from_image(info=slice_info, img_xyz=img_norm)\n",
    "        #shape_origin_save_dir = '{}/shape_origin/{}/{}'.format(save_root, group_name, subject)\n",
    "\n",
    "        #插值,归一化大小\n",
    "        #new_shape = (32, 32, 32)\n",
    "        img_xyz_3d, img_zy_x_2d = interp_image(img_xyz=img_crop_3d_xyz, new_shape_xyz=shape_norm)\n",
    "        shape_norm_save_dir = '{}/shape_norm/{}/{}'.format(save_root, group_name, subject)\n",
    "        name = '{}.png'.format(desc_info)\n",
    "        save_full_path = os.path.join(shape_norm_save_dir, name)\n",
    "        os.makedirs(shape_norm_save_dir, exist_ok=True)\n",
    "        cv2.imwrite(save_full_path, img_zy_x_2d)\n",
    "\n",
    "        sub_path = '{}/{}'.format(subject, name)\n",
    "        cls = [1, 0][sub_path.endswith('_0.png')] # *_0.png结尾的,表示无召回，假阳\n",
    "        group_data_info_list += [(sub_path, cls)]\n",
    "\n",
    "    return group_data_info_list\n",
    "\n",
    "# test\n",
    "# param = group_params_list[2]\n",
    "# process_one_group_data(group_name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:27:02.474482Z",
     "start_time": "2021-11-11T07:27:02.460181Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def aneu_eval_auc_indicator(eval_patch_info_list):\n",
    "    # seg lesion/slice patch props auc calc\n",
    "    auc_indicator_base_slice = []\n",
    "    auc_indicator_base_lesion = {}\n",
    "    \n",
    "    \n",
    "    all_slice_patch_count = {'pos': 0, 'neg': 0, 'all': 0}\n",
    "    seg_slice_patch_count = {'pos': 0, 'neg': 0, 'all': 0}\n",
    "    seg_lesion_count = {'pos': set(), 'neg': set(), 'all': set()}\n",
    "    case_count = {'pos': set(), 'neg': set(), 'all': set()}\n",
    "    all_lesion_count = {'seg': set(), 'gt': set(), 'all': set()}\n",
    "    match_gt_lesion_count = set()\n",
    "    gt_sample_lesion_count = set()\n",
    "    \n",
    "    \n",
    "    # stage1 slice patch and lesion match gt info\n",
    "    for sub_path in eval_patch_info_list:\n",
    "        #eg: x151_y127_z172_w32_h32_d32_s0.39_seg_neg_5_0.png\n",
    "        series_name, slice_patch_info = sub_path.split('/')\n",
    "        *slice_info, seg_gt_label, pos_neg_label, inst_index, recall_inst_index = slice_patch_info.split('_')\n",
    "        \n",
    "        # all\n",
    "        slice_patch_index = sub_path\n",
    "        lesion_index = f'{series_name};{inst_index}'\n",
    "        \n",
    "        all_slice_patch_count['all'] += 1  # 全部层面: GT+SEG\n",
    "        case_count['all'].add(series_name) # 全部病例: 阴性+阳性\n",
    "        lesion_key = f'{series_name};{seg_gt_label};{inst_index}'\n",
    "        all_lesion_count['all'].add(lesion_key)\n",
    "        \n",
    "        if 'gt' == seg_gt_label:\n",
    "            case_count['pos'].add(series_name) # 阳性病例\n",
    "            all_slice_patch_count['pos'] += 1            \n",
    "            \n",
    "            gt_lesion_key = f'{series_name};{inst_index}' # var:inst_index same to var:recall_inst_index\n",
    "            gt_sample_lesion_count.add(gt_lesion_key) # 阳性病灶(GT)\n",
    "            all_lesion_count['gt'].add(lesion_key)            \n",
    "            \n",
    "            # continue\n",
    "        elif 'seg' == seg_gt_label:\n",
    "            # count\n",
    "            seg_slice_patch_count['all'] += 1  #\n",
    "            seg_slice_patch_count[pos_neg_label] += 1\n",
    "            all_slice_patch_count[pos_neg_label] += 1\n",
    "            \n",
    "            seg_lesion_key = f'{series_name};{inst_index}'\n",
    "            seg_lesion_count['all'].add(seg_lesion_key)\n",
    "            seg_lesion_count[pos_neg_label].add(seg_lesion_key)\n",
    "            all_lesion_count['seg'].add(lesion_key)\n",
    "            \n",
    "            if 'pos' == pos_neg_label:\n",
    "                recall_inst_index_list = recall_inst_index.rsplit('.png', maxsplit=1)[0]\n",
    "                recall_inst_index_list = recall_inst_index_list.split('&')\n",
    "                for recall_inst_index in recall_inst_index_list:\n",
    "                    match_gt_lesion_key = f'{series_name};{recall_inst_index}'\n",
    "                    match_gt_lesion_count.add(match_gt_lesion_key)\n",
    "            \n",
    "            # auc\n",
    "            s1_score = float(slice_info[-1][1:])\n",
    "            # 1. slice patch level of seg props only\n",
    "            #slice_type = int(_cls)\n",
    "            slice_type = int('pos' == pos_neg_label)\n",
    "            auc_indicator_base_slice += [(slice_patch_index, s1_score, slice_type)]\n",
    "            \n",
    "            # 2. lesion level of seg props only            \n",
    "            #lesion_recall_type = int(_cls)\n",
    "            lesion_recall_type = int('pos' == pos_neg_label)\n",
    "            # 2.1 lesion in stage1\n",
    "            auc_indicator_base_lesion.setdefault(lesion_index, [-1, lesion_recall_type])\n",
    "            cur_lesion_score_s1 = auc_indicator_base_lesion[lesion_index][0]\n",
    "            auc_indicator_base_lesion[lesion_index][0] = max(cur_lesion_score_s1, s1_score)      \n",
    "            \n",
    "        else:\n",
    "            raise Exception('unknown origin type: {} in {}'.format(seg_gt_label, sub_path))\n",
    "    \n",
    "    case_count['neg'] = case_count['all'] - case_count['pos']\n",
    "    print('case count:', {k:len(v) for k, v in case_count.items()})\n",
    "    print('all lesion count:', {k:len(v) for k, v in all_lesion_count.items()})\n",
    "    seg_lesion_count_map = {k:len(v) for k, v in seg_lesion_count.items()}\n",
    "    print('seg lesion count:', seg_lesion_count_map, ',and max match gt lesion:', len(match_gt_lesion_count))\n",
    "    \n",
    "    \n",
    "    # slice count \n",
    "    print('seg slice count:', seg_slice_patch_count)\n",
    "    print('all slice count:', all_slice_patch_count)\n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "    seg_auc_info_list = []\n",
    "    group_name_list= ['seg-slice-auc', 'seg-lesion-auc']\n",
    "    for group_name, seg_slice_info in zip(group_name_list, [auc_indicator_base_slice, [[k]+v for k, v in auc_indicator_base_lesion.items()]]):\n",
    "        pred_score_list = [_[1] for _ in seg_slice_info]\n",
    "        label_list = [_[2] for _ in seg_slice_info]\n",
    "        all_neg = all([0 == _ for _ in label_list])\n",
    "        all_pos = all([1 == _ for _ in label_list])\n",
    "        if all_neg or all_pos:\n",
    "            auc_score = -1.00\n",
    "        else:\n",
    "            y_pred_list = np.array(pred_score_list)\n",
    "            y_gt_list = np.array(label_list)\n",
    "            auc_score = roc_auc_score(y_true=y_gt_list, y_score=y_pred_list)\n",
    "        info = f'{group_name}={auc_score:.4f}'\n",
    "        seg_auc_info_list += [info]\n",
    "        \n",
    "    print('AUC', seg_auc_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T07:53:46.581515Z",
     "start_time": "2021-11-11T07:27:02.476091Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ train ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend MultiprocessingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总条目: 39\n",
      "case count: {'pos': 1, 'neg': 0, 'all': 1}\n",
      "all lesion count: {'seg': 4, 'gt': 1, 'all': 5}\n",
      "seg lesion count: {'pos': 1, 'neg': 3, 'all': 4} ,and max match gt lesion: 1\n",
      "seg slice count: {'pos': 12, 'neg': 15, 'all': 27}\n",
      "all slice count: {'pos': 24, 'neg': 15, 'all': 39}\n",
      "AUC ['seg-slice-auc=0.7972', 'seg-lesion-auc=0.8333']\n",
      "================ valid ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   1 out of   1 | elapsed:    7.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend MultiprocessingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总条目: 39\n",
      "case count: {'pos': 1, 'neg': 0, 'all': 1}\n",
      "all lesion count: {'seg': 4, 'gt': 1, 'all': 5}\n",
      "seg lesion count: {'pos': 1, 'neg': 3, 'all': 4} ,and max match gt lesion: 1\n",
      "seg slice count: {'pos': 12, 'neg': 15, 'all': 27}\n",
      "all slice count: {'pos': 24, 'neg': 15, 'all': 39}\n",
      "AUC ['seg-slice-auc=0.7972', 'seg-lesion-auc=0.8333']\n",
      "================ test ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   1 out of   1 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend MultiprocessingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总条目: 39\n",
      "case count: {'pos': 1, 'neg': 0, 'all': 1}\n",
      "all lesion count: {'seg': 4, 'gt': 1, 'all': 5}\n",
      "seg lesion count: {'pos': 1, 'neg': 3, 'all': 4} ,and max match gt lesion: 1\n",
      "seg slice count: {'pos': 12, 'neg': 15, 'all': 27}\n",
      "all slice count: {'pos': 24, 'neg': 15, 'all': 39}\n",
      "AUC ['seg-slice-auc=0.7972', 'seg-lesion-auc=0.8333']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   1 out of   1 | elapsed:    6.8s finished\n"
     ]
    }
   ],
   "source": [
    "for group_name, group_params in params_group_map.items():\n",
    "    if group_name in [\n",
    "        # 'train',\n",
    "        # 'valid',\n",
    "        # 'test',\n",
    "    ]:\n",
    "        continue\n",
    "    print('{0} {1} {0}'.format('='*16, group_name))\n",
    "    group_params_list = sorted(group_params.values())\n",
    "    results = Parallel(n_jobs=cpu_count()//4, verbose=5, backend='multiprocessing')(\\\n",
    "            delayed(process_one_group_data)(group_name, _) for _ in group_params_list[:])\n",
    "    #\n",
    "    save_name = os.path.join(save_root, 'part_{}.txt'.format(group_name))\n",
    "    info_list = []\n",
    "    with open(save_name, 'w') as fout:\n",
    "        for case_info in results:\n",
    "            for slice_info in case_info:\n",
    "                desc, _cls = slice_info\n",
    "                info_list += ['{}\\t{}'.format(desc, _cls)]\n",
    "                #print(desc, _cls, file=fout)\n",
    "        print('数据总条目:', len(info_list))\n",
    "        fout.write('\\n'.join(info_list))\n",
    "        # 分割病灶\n",
    "        data_info = [_.split()[0] for _ in info_list]\n",
    "        aneu_eval_auc_indicator(eval_patch_info_list=data_info)\n",
    "    shape_norm_save_dir = '{}/shape_norm/{}'.format(save_root, group_name)\n",
    "    shutil.copy(save_name, shape_norm_save_dir)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "95e8a0b7daaaf4f896aaac41afd7e7872ead05aed45e85579bb0311e7fb86a1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
